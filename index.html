<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultrasound Report Generation DPO </title>
    <!-- MathJax for LaTeX rendering -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Ultrasound Report Generation DPO </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Nikkhah, Ali</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Heidari, Moein</a><sup>*</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>














<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
  <!-- ===== HERO ===== -->
  <section class="hero is-primary is-bold">
    <div class="hero-body">
      <div class="container has-text-centered">
        <h1 class="title is-2">Ultrasound Report Generation with DPO</h1>
        <h2 class="subtitle is-4">&amp; Survey of Open-Source Biomedical Language Models</h2>
      </div>
    </div>
  </section>
      <section>
        <h1>Medical NLP Resources and Tools for Ultrasound Entity Recognition</h1>
        <p>This page provides a summary of various resources, APIs, and models for Named Entity Recognition (NER) in medical texts, especially focused on ultrasound data. These resources include medical ontologies, NLP models, and specific datasets for efficient and accurate entity extraction from medical reports.</p>
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Medical-NER Findings & Triplet Extraction Flow</h2>
    <div class="content">
      <h3 class="title is-4">NER Model Performance - BioBERT & Family</h3>
      <p><strong>BioBERT</strong> (and related models like BlueBERT/ClinicalBERT) outperform vanilla BERT and SciBERT by a margin, due to their pre-training on PubMed and clinical notes. This enables better recognition of domain-specific phrases and negations.</p>
      <p>Reported F1 improvements (2-6 percentage points over BERT/SciBERT) are primarily from better recall of edge-case entities and fewer false positives.</p>

      <h3 class="title is-4">Implications for Triplet Extraction</h3>
      <p>A strong NER stage is crucial since any errors in entity recognition or hallucinated entities will propagate to the triplet extraction stage. Using a BioBERT-style model as the backbone, especially fine-tuned on ultrasound reports, will result in cleaner <code>{entity, position, exist}</code> triples.</p>

      <h4 class="subtitle is-5">Negation and Uncertainty Detection</h4>
      <p>Tools like <strong>NegBio</strong> (which employs dependency-pattern rules) can slot in after NER to determine the "existence" flag, improving the triplet consistency.</p>

      <h4 class="subtitle is-5">Position Phrase Parsing</h4>
      <p>Ultrasound-specific positions (e.g., "sub-hepatic region", "right adnexa") require curated lexicons or relation parsers like OSCAR/NegBio to map phrases to standard anatomical locations.</p>

      <h3 class="title is-4">Ultrasound-Specific Considerations</h3>
      <ul>
        <li>Ultrasound reports are typically shorter and feature more shorthand abbreviations (e.g., "Rt ov nl", "CBD 7 mm"). Thus, domain-adapted tokenization and abbreviation mapping are essential during preprocessing.</li>
        <li>Many findings come with size measurements, which can either be handled as separate entity tokens (e.g., "cyst") plus an attribute triple (e.g., "size, 3 cm, true") or embedded within the entity span depending on the downstream task.</li>
      </ul>

      <h3 class="title is-4">End-to-End NER + Triplet Flow</h3>
      <p>Below is the revised pipeline for processing ultrasound reports:</p>
      <ol>
        <li><strong>Pre-process & Tokenize:</strong> Expand abbreviations, keep measurement tokens.</li>
        <li><strong>NER with BioBERT-family:</strong> Fine-tune BioBERT on manually-annotated ultrasound sentences for entity recognition.</li>
        <li><strong>Negation Detection:</strong> Use NegBio (or similar rule-based methods) to set the "exist" flag (True/False/Unknown).</li>
        <li><strong>Position Parsing:</strong> Use RadGraph or rule-based models for anatomical phrase matching (e.g., "left ovary").</li>
        <li><strong>Triplet Assembly:</strong> Assemble <code>{entity, position, exist}</code> triples.</li>
        <li><strong>Post-filtering:</strong> Optionally filter inconsistent triples (e.g., remove entities with "exist = False" or empty positions).</li>
      </ol>

      <h3 class="title is-4">Entity Translation & MedKLIP Integration</h3>
      <p>Incorporating an <strong>Entity Translation</strong> layer, inspired by MedKLIP’s approach, will enhance the robustness and generalization of the NER system. Here’s how:</p>

      <ol>
        <li><strong>Canonical Concept Lookup:</strong> Map each raw entity to a canonical concept (e.g., "cyst" → UMLS CUI) using internal lookups or APIs.</li>
        <li><strong>Definition Sentence Retrieval:</strong> Use knowledge sources (e.g., Wikipedia, Radiopaedia) to fetch definitions for each entity.</li>
        <li><strong>Text-Encode Definitions:</strong> Encode these definitions with a model like ClinicalBERT to obtain embeddings, which carry richer semantic meaning.</li>
        <li><strong>Cache Vectors:</strong> Cache the resulting entity vectors for speed and continual updates.</li>
      </ol>

      <h3 class="title is-4">Final Triplet Assembly</h3>
      <p>The final output format of each triplet includes:</p>
      <pre>
        {
          "entity": {
            "text": "cyst",
            "cui": "C0010692",
            "embedding": [ … ]
          },
          "position": {
            "label": "left ovary",
            "prompt_embedding": [ … ]
          },
          "exist": "TRUE"
        }
      </pre>

      <h3 class="title is-4">Practical Roadmap</h3>
      <p>The following milestones outline the implementation effort:</p>
      <ul>
        <li><strong>MVP:</strong> NER + NegBio + lookup table of ~150 ultrasound entities and definitions (1-2 weeks)</li>
        <li><strong>Fine-tuning:</strong> Fine-tune BioBERT on ~500 annotated ultrasound sentences (2-3 days GPU)</li>
        <li><strong>CUI Linker:</strong> Build CUI linker with QuickUMLS + rules (1 week)</li>
        <li><strong>Optional:</strong> Train relation-aware model (PURE or RadGraph) for position dependencies (later)</li>
      </ul>

      <h3 class="title is-4">Key Takeaways</h3>
      <ul>
        <li>Maintain the solid NER/negation backbone.</li>
        <li>Insert a lightweight entity-translation module that turns each span into a knowledge-rich definition vector.</li>
        <li>The richer embeddings will improve synonym collapse, zero-shot robustness, and multi-modal adaptability.</li>
      </ul>

      <p>Let me know which part you'd like to explore next—definition harvesting, CUI mapping, or embedding architecture!</p>
    </div>
  </div>
</section>

        <h2>1. Core Ontology and Medical Databases</h2>
        <table border="1" cellpadding="5">
            <thead>
                <tr>
                    <th>Tier</th>
                    <th>Resource / API</th>
                    <th>What it gives you (Entity, Location, Synonyms)</th>
                    <th>How to integrate</th>
                    <th>Notes & Links</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Core Ontology</strong></td>
                    <td><strong>UMLS Metathesaurus</strong></td>
                    <td>Over 4 million CUIs covering disorders, findings, anatomy, devices, procedures. Synonym lists included.</td>
                    <td>1. Download yearly release <br> 2. Filter by semantic types (e.g., T033 – “Finding”, T023 – “Body part”) <br> 3. Generate JSON gazetteer for entity auto-completion.</td>
                    <td>“One-stop shop” for comprehensive medical terms. Filter aggressively. <br> <a href="https://www.nlm.nih.gov/research/umls/Snomed/SNOMED_CT_User_Guide_20080731.pdf?utm_source=chatgpt.com">SNOMED CT User Guide</a></td>
                </tr>
                <tr>
                    <td></td>
                    <td><strong>SNOMED CT</strong></td>
                    <td>Gold-standard hierarchy for clinical findings with explicit anatomical site relations.</td>
                    <td>Normalize location phrases like "RUQ", "right liver lobe", "segment VI" using the same concept ID.</td>
                    <td>Public release via NLM license. <a href="https://www.rsna.org/practice-tools/data-tools-and-standards/radlex-radiology-lexicon?utm_source=chatgpt.com">RadLex</a></td>
                </tr>
                <tr>
                    <td></td>
                    <td><strong>RadLex</strong></td>
                    <td>Imaging-specific lexicon (lesions, artifacts, views, ultrasound probes, planes).</td>
                    <td>Append to UMLS for disambiguating imaging jargon.</td>
                    <td>Free from RSNA. <a href="https://www.rsna.org/practice-tools/data-tools-and-standards/radlex-radiology-lexicon?utm_source=chatgpt.com">RadLex radiology lexicon</a></td>
                </tr>
                <tr>
                    <td><strong>Light-weight, use-from-Python</strong></td>
                    <td><strong>QuickUMLS / medSpaCy-QuickUMLS</strong></td>
                    <td>Fast, fuzzy string-to-UMLS matcher returning [CUI, term, similarity].</td>
                    <td>Use as post-processor to match LLM proposals to UMLS terms with similarity above a set threshold.</td>
                    <td>Pip-installable, no license hurdles. <a href="https://github.com/Georgetown-IR-Lab/QuickUMLS?utm_source=chatgpt.com">QuickUMLS GitHub</a></td>
                </tr>
                <tr>
                    <td><strong>Structured location schema (ultrasound-friendly)</strong></td>
                    <td><strong>FMA (Foundational Model of Anatomy)</strong></td>
                    <td>Parent/child relations (e.g., "liver → lobe → segment"). Ideal for hierarchical location labels.</td>
                    <td>Use a three-level subset (organ, lobe/quadrant, sub-region) for location labels.</td>
                    <td></td>
                </tr>
                <tr>
                    <td><strong>Specialty Add-ons</strong></td>
                    <td><strong>HPO (phenotypes for obstetric US), LOINC (panels for vascular flow studies)</strong></td>
                    <td>Use if covering subspecialties like obstetric ultrasound or vascular studies.</td>
                    <td></td>
                    <td></td>
                </tr>
            </tbody>
        </table>
    </section>

    <section>
        <h2>2. Hybrid Approaches and Pre-trained Models</h2>
        <table border="1" cellpadding="5">
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Training Corpus</th>
                    <th>Open-Source?</th>
                    <th>Params (M)</th>
                    <th>PubMedQA Acc. (%)</th>
                    <th>BC5-Disease F1 (%)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>BioBERT</td>
                    <td>PubMed + PMC abstracts</td>
                    <td class="has-text-success">✔</td>
                    <td>110</td>
                    <td>60.2</td>
                    <td>84.7</td>
                </tr>
                <tr>
                    <td>SciBERT</td>
                    <td>Semantic Scholar</td>
                    <td class="has-text-success">✔</td>
                    <td>110</td>
                    <td>57.4</td>
                    <td>84.5</td>
                </tr>
                <tr>
                    <td>BlueBERT</td>
                    <td>PubMed + MIMIC-III</td>
                    <td class="has-text-success">✔</td>
                    <td>110</td>
                    <td>49.1</td>
                    <td>83.0</td>
                </tr>
                <tr>
                    <td>BioGPT-Large</td>
                    <td>PubMed abstracts</td>
                    <td class="has-text-success">✔</td>
                    <td>1500</td>
                    <td><strong>78.2</strong></td>
                    <td>45.0†</td>
                </tr>
                <tr>
                    <td>PMC LLaMA-13B</td>
                    <td>PMC full-text</td>
                    <td class="has-text-success">✔</td>
                    <td>13000</td>
                    <td>76.8</td>
                    <td>—</td>
                </tr>
            </tbody>
        </table>
    </section>


  <!-- ===== MODEL TABLE SECTION ===== -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Top Performing Open-Source Biomedical LMs</h2>
      <div class="content">
        <table class="table is-hoverable is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>Training Corpus</th>
              <th>Open-Source?</th>
              <th>Params (M)</th>
              <th>PubMedQA Acc. (%)</th>
              <th>BC5-Disease F1 (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>BioBERT</td><td>PubMed + PMC abstracts</td><td class="has-text-success">✔</td><td>110</td><td>60.2</td><td>84.7</td></tr>
            <tr><td>SciBERT</td><td>Semantic Scholar</td><td class="has-text-success">✔</td><td>110</td><td>57.4</td><td>84.5</td></tr>
            <tr><td>BlueBERT</td><td>PubMed + MIMIC-III</td><td class="has-text-success">✔</td><td>110</td><td>49.1</td><td>83.0</td></tr>
            <tr><td>PubMedBERT</td><td>PubMed abstracts/full-text</td><td class="has-text-success">✔</td><td>110</td><td>55.8</td><td>85.6</td></tr>
            <tr><td>BioGPT-Large</td><td>PubMed abstracts</td><td class="has-text-success">✔</td><td>1500</td><td><strong>78.2</strong></td><td>45.0†</td></tr>
            <tr><td>BioMedLM</td><td>PubMed + PMC full-text</td><td class="has-text-success">✔</td><td>2700</td><td>74.4</td><td>—</td></tr>
            <tr><td>PMC&nbsp;LLaMA-13B</td><td>PMC full-text</td><td class="has-text-success">✔</td><td>13000</td><td>76.8</td><td>—</td></tr>
          </tbody>
        </table>
        <p class="is-size-7">† BioGPT numbers are zero-shot; all others are fine-tuned on BLURB. </p>
      </div>
    </div>
  </section>
  <section>
    <h2>3. Comparison of NLP Methods for Ultrasound Entity Recognition</h2>
    <p>In the process of extracting and tagging entities, locations, and existence from ultrasound reports, various NLP methods can be employed. These methods can be broadly categorized into classic NLP, medical NLP, ontology-based approaches, and transformer-based models. Each method comes with its strengths and applications depending on the complexity and specificity of the task.</p>
    
    <h3>Classic NLP Methods</h3>
    <p>Classic NLP methods focus on general-purpose text processing tasks such as tokenization, part-of-speech tagging, and named entity recognition. These methods can be adapted for medical texts, but they may require additional customization and domain-specific tuning for medical applications.</p>
    
    <table border="1" cellpadding="5">
        <thead>
            <tr>
                <th>Method</th>
                <th>Description</th>
                <th>Pros</th>
                <th>Cons</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>spaCy (Classic NLP)</strong></td>
                <td>A robust NLP library for general-purpose tasks like tokenization, POS tagging, and NER.</td>
                <td>Fast, well-documented, customizable with pre-trained models.</td>
                <td>May lack domain-specific training, requiring fine-tuning for medical data.</td>
                <td>General entity recognition from ultrasound reports, but with limited medical accuracy.</td>
            </tr>
            <tr>
                <td><strong>NLTK (Classic NLP)</strong></td>
                <td>A toolkit for NLP tasks, including tokenization, POS tagging, and entity extraction.</td>
                <td>Widely used, offers flexibility in preprocessing and experimentation.</td>
                <td>May not perform as efficiently on large datasets; lacks pre-trained domain models.</td>
                <td>Entity extraction when domain-specific models are unavailable.</td>
            </tr>
        </tbody>
    </table>

    <h3>Medical NLP Methods</h3>
    <p>Medical NLP models, like MedSpaCy, are designed to work specifically with medical texts and provide improved performance for tasks like extracting medical entities and understanding medical terminology.</p>

    <table border="1" cellpadding="5">
        <thead>
            <tr>
                <th>Method</th>
                <th>Description</th>
                <th>Pros</th>
                <th>Cons</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>MedSpaCy (Medical NLP)</strong></td>
                <td>An extension of spaCy optimized for medical entities, offering pre-trained models for clinical NER.</td>
                <td>Well-suited for medical text, can identify disease, anatomical locations, and clinical terms.</td>
                <td>Requires specialized setup and dependency management.</td>
                <td>Clinical reports, including ultrasound, where domain-specific terminology is used.</td>
            </tr>
        </tbody>
    </table>

    <h3>Ontology-based Methods</h3>
    <p>Ontology-based approaches leverage medical ontologies, such as UMLS, SNOMED CT, and RadLex, to map extracted entities to standardized medical concepts. These methods ensure consistency and precision in medical terminology, which is especially useful when dealing with complex medical texts.</p>

    <table border="1" cellpadding="5">
        <thead>
            <tr>
                <th>Method</th>
                <th>Description</th>
                <th>Pros</th>
                <th>Cons</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>UMLS (Unified Medical Language System)</strong></td>
                <td>A comprehensive system that links biomedical vocabularies and provides a unified view of medical concepts.</td>
                <td>Extensive coverage of medical terms and relationships.</td>
                <td>Large and complex; requires API access and data filtering for specific tasks.</td>
                <td>Standardizing medical terminology and ensuring consistency across ultrasound data.</td>
            </tr>
            <tr>
                <td><strong>SNOMED CT</strong></td>
                <td>A global standard for clinical terms and relationships, widely used for medical coding and clinical data exchange.</td>
                <td>Provides a structured hierarchy for entities and relationships.</td>
                <td>Can be complex to implement and requires deep integration into systems.</td>
                <td>Mapping locations and clinical findings in ultrasound reports.</td>
            </tr>
            <tr>
                <td><strong>RadLex</strong></td>
                <td>A lexicon specifically designed for radiology, offering standardized terms for imaging findings, including ultrasound-specific probes and views.</td>
                <td>Well-suited for imaging-specific data and terminology.</td>
                <td>Limited scope compared to broader ontologies like UMLS.</td>
                <td>Mapping ultrasound imaging terms and findings (e.g., "cyst," "lesion").</td>
            </tr>
        </tbody>
    </table>

    <h3>BERT-based Approaches</h3>
    <p>Transformer-based models like BERT and its variants (BioBERT, ClinicalBERT) have revolutionized the field of medical NLP by offering pre-trained models that excel at understanding the complex semantics of medical texts, including ultrasound reports.</p>

    <table border="1" cellpadding="5">
        <thead>
            <tr>
                <th>Method</th>
                <th>Description</th>
                <th>Pros</th>
                <th>Cons</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>BioBERT</strong></td>
                <td>A pre-trained BERT model for biomedical text mining, trained on large biomedical corpora like PubMed.</td>
                <td>Excellent for biomedical entity recognition and understanding domain-specific language.</td>
                <td>Requires fine-tuning for specific tasks, computationally intensive.</td>
                <td>Advanced entity recognition in ultrasound reports and medical diagnoses.</td>
            </tr>
            <tr>
                <td><strong>ClinicalBERT</strong></td>
                <td>A fine-tuned version of BERT, pre-trained on clinical text data, ideal for clinical NER tasks.</td>
                <td>Great for clinical documents, including ultrasound reports.</td>
                <td>May not perform as well on non-clinical data.</td>
                <td>Extraction of entities like diseases and treatments from ultrasound reports.</td>
            </tr>
        </tbody>
    </table>

    <h3>Saving the Tagged Data</h3>
    <p>After the entities have been extracted using any of the above methods, the tagged data can be saved in a variety of formats, such as CSV, JSON, or a database, for further analysis, training, or integration into larger workflows.</p>

    <h3>Comparison of Tagging Results Across Different Methods</h3>
    <p>The effectiveness of these methods can be compared using evaluation metrics like precision, recall, and F1-score. Some models like BioBERT and MedSpaCy, trained specifically on medical data, tend to outperform general-purpose models like spaCy in extracting medical entities.</p>
</section>
          <section>
    <h2>4. Unsupervised Evaluation of Models for Ultrasound Entity Recognition</h2>
    <p>Unsupervised evaluation techniques are essential when ground truth data is limited or unavailable. These methods focus on evaluating the consistency, coherence, and reliability of annotations across various reports. Below, we outline some effective unsupervised evaluation approaches for Named Entity Recognition (NER) in ultrasound reports.</p>

    <h3>Evaluation Approaches</h3>
    <table border="1" cellpadding="5">
        <thead>
            <tr>
                <th>Evaluation Method</th>
                <th>Description</th>
                <th>Use Case</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Entity Consistency Check</strong></td>
                <td>Measures how consistently the model extracts the same entities across similar reports. If the same entity is extracted with varying labels (e.g., "Cyst" vs. "Mass"), it signals inconsistency in the model's recognition.</td>
                <td>Useful for checking if terms like "Tumor" are always labeled consistently in different reports.</td>
            </tr>
            <tr>
                <td><strong>Clustering-Based Evaluation</strong></td>
                <td>Clustering extracted entities to check if similar entities are grouped together. For instance, "Liver Cyst," "Hepatic Cyst," and "Cyst in Liver" should be clustered together.</td>
                <td>To assess whether similar medical entities are classified together, ensuring accuracy in extracting anatomical findings.</td>
            </tr>
            <tr>
                <td><strong>Entity Relationship Consistency</strong></td>
                <td>Evaluates if entities are correctly related to anatomical positions. For example, "Cyst" should consistently be linked to "Liver" when described as a cyst in the liver.</td>
                <td>To verify that anatomical locations are correctly matched with associated entities (e.g., "Right Kidney" with "Cyst").</td>
            </tr>
            <tr>
                <td><strong>Named Entity Linking (NEL) Accuracy</strong></td>
                <td>Measures the model's ability to link extracted entities to a knowledge base such as UMLS or SNOMED CT. This ensures that the correct medical terms are used consistently.</td>
                <td>Essential for checking the correctness of terms like "Cyst" by matching them with standard medical databases.</td>
            </tr>
            <tr>
                <td><strong>Similarity Metrics</strong></td>
                <td>Uses semantic similarity metrics (e.g., Cosine Similarity, Jaccard Index) to assess whether similar terms are extracted consistently. For example, checking if "Liver" and "Hepatic" are identified as referring to the same anatomical region.</td>
                <td>Helps evaluate the semantic accuracy of entity extraction by ensuring that synonymous terms are recognized as identical concepts.</td>
            </tr>
        </tbody>
    </table>

    <p>These unsupervised evaluation techniques help identify issues in entity extraction consistency and ensure that the model is performing reliably across a wide range of ultrasound reports.</p>

    <h2>5. Triplet Extraction Using LLMs (e.g., GPT-4o) for Ultrasound Data Labeling</h2>
    <p>Using Large Language Models (LLMs) like GPT-4o for triplet extraction in ultrasound reports involves identifying key entities, anatomical locations, and their existence status (e.g., Present, Absent, Uncertain). The feasibility of this approach depends on fine-tuning LLMs on ultrasound-specific data and using a well-defined framework for triplet extraction.</p>

    <h3>Feasibility of Using LLMs for Ultrasound Data Labeling</h3>
    <p>LLMs like GPT-4o can be highly effective for ultrasound data labeling due to their foundational knowledge of medical texts, which includes anatomy, diseases, and medical terminology. However, to ensure accuracy, these models need to be fine-tuned on ultrasound-specific datasets, which helps the model learn the nuanced language of ultrasound reports.</p>

    <h4>Key Considerations:</h4>
    <ul>
        <li><strong>High Accuracy:</strong> LLMs can be trained to achieve high accuracy, but fine-tuning with ultrasound-specific reports is essential.</li>
        <li><strong>Cost-Effectiveness:</strong> Using LLMs for annotation reduces the need for manual expert annotation, which can be expensive.</li>
        <li><strong>Speed:</strong> LLMs can process large datasets rapidly, making them ideal for automating the annotation of ultrasound data.</li>
    </ul>

    <h3>How to Ensure LLM Does a Fine Job Labeling Ultrasound Data</h3>
    <p>To ensure that LLMs like GPT-4o accurately label ultrasound reports, the following strategies should be applied:</p>

    <h4>a. Fine-Tuning the Model</h4>
    <p>Fine-tuning the LLM on ultrasound-specific datasets is crucial. This allows the model to recognize medical terms and contextual nuances specific to ultrasound reports (e.g., “lesion in the left kidney”). Fine-tuning datasets should include pre-annotated ultrasound reports in the format of {Entity, Location, Existence}.</p>

    <h4>b. Using Few-Shot Prompting</h4>
    <p>In cases where labeled data is limited, few-shot learning can be applied by providing the LLM with a few examples of ultrasound reports with their corresponding annotations. This can help the model generalize to new data.</p>

    <h4>c. Incorporating Medical Knowledge Bases</h4>
    <p>Integrating external knowledge bases like UMLS or SNOMED CT into the LLM helps ensure that extracted entities and locations are consistent with standardized medical terms.</p>

    <h4>d. Confidence Scoring</h4>
    <p>LLMs can provide confidence scores for their predictions. Low-confidence predictions should be flagged for human review. For instance, the model might output the following:</p>
    <ul>
        <li>{Entity: Cyst, Position: Left kidney, Exist: Present, Confidence: 95%}</li>
        <li>{Entity: Tumor, Position: Liver, Exist: Uncertain, Confidence: 65%}</li>
    </ul>

    <h3>Triplet Extraction Example</h3>
    <p>The LLM can be prompted with the following structure to extract the triplets from an ultrasound report:</p>
    <pre>
    Prompt: “Extract the medical entity, its anatomical location, and its existence from the following ultrasound report:
    ‘A small tumor was found in the left liver lobe, but its presence is uncertain.’”
    </pre>
    <p>Expected Output: 
    <ul>
        <li>{Entity: Tumor, Location: Left liver lobe, Existence: Uncertain}</li>
    </ul></p>

    <p>By iterating on this process and adjusting the model’s prompts and training data, the LLM can accurately and consistently extract triplets from ultrasound reports.</p>
</section>


  <!-- ===== PLOTS SECTION ===== -->
  <section class="section has-background-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Model Evolution – Size × Performance</h2>
      <div class="columns is-variable is-8">
        <div class="column">
          <figure class="image is-3by2">
            <img src="static/images/plot_qa.png" alt="Bubble plot of PubMedQA accuracy over publication year" />
          </figure>
          <p class="has-text-centered is-size-6 mt-2"><em>Figure 1</em> – PubMedQA accuracy rises with newer &amp; larger models.</p>
        </div>
        <div class="column">
          <figure class="image is-3by2">
            <img src="static/images/plot_ner.png" alt="Bubble plot of BC5-disease F1 over publication year" />
          </figure>
          <p class="has-text-centered is-size-6 mt-2"><em>Figure 2</em> – Disease-NER performance has plateaued since 2019.</p>
        </div>
      </div>
    </div>
  </section>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


  <!-- ===== REFERENCES SECTION ===== -->
  <section class="section has-background-light">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Key References</h2>
      <div class="content is-size-6">
        <ul>
          <li>Lee J. et al. <em>BioBERT: a pre-trained biomedical language representation model</em>. ACL 2019.</li>
          <li>Luo R. et al. <em>BioGPT: generative pre-trained transformer for biomedical text generation</em>. bioRxiv 2022.</li>
          <li>Nori H. et al. <em>Toward trustworthy DPO for medical report generation</em>. NAACL 2025.</li>
        </ul>
      </div>
    </div>
  </section>







  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>









